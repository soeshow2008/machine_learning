1.2019,<Behavior Sequence Transformer for E-commerce Recommendation in Alibaba>
2.https://arxiv.org/abs/1905.06874v1
3.Multi-head Self-attention机制
4.muti-head是kqv的拆解为多个领域，分别做attention，然后cancat，相当于并行做了多个attention；然后多层更新的是query，kv是复用的。
