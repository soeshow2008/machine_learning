# -*- coding: utf-8 -*-

import tensorflow as tf
import numpy as np
import time
import matplotlib.pyplot as plt

# 启用 Eager Execution 模式
tf.enable_eager_execution();

base_size = 3
seq_len = 8
ad_emb_size = 48

inputs = tf.random.uniform([base_size, seq_len, ad_emb_size])
inputs = tf.expand_dims(inputs, -1)

filter_sizes = [3, 4, 5];
num_filters = 7;

pooled_outputs = []
for i, filter_size in enumerate(filter_sizes):
    with tf.name_scope("conv-maxpool-%s" % filter_size):
        # Convolution Layer
        filter_shape = [filter_size, ad_emb_size, 1, num_filters]
        W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name="W")
        b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name="b")
        conv = tf.nn.conv2d(
            inputs,
            W,
            strides=[1, 1, 1, 1],
            padding="VALID",
            name="conv")
        # Apply nonlinearity
        h = tf.nn.relu(tf.nn.bias_add(conv, b), name="relu")
        # Max-pooling over the outputs
        pooled = tf.nn.max_pool(
            h,
            ksize=[1, seq_len - filter_size + 1, 1, 1],
            strides=[1, 1, 1, 1],
            padding='VALID',
            name="pool")
        pooled_outputs.append(pooled)

# Combine all the pooled features
num_filters_total = num_filters * len(filter_sizes)
h_pool = tf.concat(pooled_outputs, 3)
h_pool_flat = tf.reshape(h_pool, [-1, num_filters_total])
print(h_pool_flat)
